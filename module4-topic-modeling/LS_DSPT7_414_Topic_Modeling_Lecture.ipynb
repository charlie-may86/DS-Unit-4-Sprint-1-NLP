{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOMBkFKn6uEK"
   },
   "source": [
    "# Topic Modeling (Prepare)\n",
    "\n",
    "On Monday we talked about summarizing your documents using just token counts. Today, we're going to learn about a much more sophisticated approach - learning 'topics' from documents. Topics are a latent structure. They are not directly observable in the data, but we know they're there by reading them.\n",
    "\n",
    "> **latent**: existing but not yet developed or manifest; hidden or concealed.\n",
    "\n",
    "## Use Cases\n",
    "Primary use case: what the hell are your documents about? Who might want to know that in industry - \n",
    "* Identifying common themes in customer reviews\n",
    "* Discovering the needle in a haystack \n",
    "* Monitoring communications (Email - State Department) \n",
    "\n",
    "## Learning Objectives\n",
    "*At the end of the lesson you should be able to:*\n",
    "* Part 0: Warm-Up\n",
    "* Part 1: Describe how an LDA Model works\n",
    "* Part 2: Estimate a LDA Model with Gensim\n",
    "* Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxH0cRGX6uEL"
   },
   "source": [
    "# Part 0: Warm-Up\n",
    "How do we do a grid search? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFjplZ7r3Lyk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnyNg8sQ6uEL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boKWVkRz6uEO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 11314\n",
      "Testing Samples: 7532\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', \n",
    "                                      remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Load testing data\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', \n",
    "                                     remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "print(f'Training Samples: {len(newsgroups_train.data)}')\n",
    "print(f'Testing Samples: {len(newsgroups_test.data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPpukADi7Ofv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g9Jhb3j-7_e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JbVoIoMm8HbR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Anybody seen mouse cursor distortion running the Diamond 1024x768x256 driver?\\nSorry, don't know the version of the driver (no indication in the menus) but it's a recently\\ndelivered Gateway system.  Am going to try the latest drivers from Diamond BBS but wondered\\nif anyone else had seen this.\\n\\npost or email\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['data'][1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-39zg9a6uEQ"
   },
   "source": [
    "### GridSearch on Just Classifier\n",
    "* Fit the vectorizer and prepare BEFORE it goes into the gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2q3NmHEo6uEQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate vectorizer\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "# Transform the training data\n",
    "X_train = vect.fit_transform(newsgroups_train['data'])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OfA7KNQ6uEU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:  1.3min remaining:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': [1, 2, 5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_1 = {\n",
    "    'min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "# Instantiate classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# GridSearch\n",
    "gs1 = GridSearchCV(clf, params_1, cv=5, n_jobs=-1, verbose=1)\n",
    "gs1.fit(X_train, newsgroups_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6574148851336595"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDkMaXvG83Zt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 101631)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = vect.transform([\"The new york yankees are the best team in the region.\"])\n",
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMq_hw5W6uEX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.predict(test_sample)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.baseball'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target_names'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdVTuXKl6uEZ"
   },
   "source": [
    "### GridSearch with BOTH the Vectoizer & Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97TjUtoI6uEZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acce...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=42,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (10, None), 'vect__min_df': (2, 5),\n",
       "                         'vect__stop_words': (None, 'english')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Create a pipeline with a vectorize and a classifier\n",
    "# 2. Use Grid Search to optimize the entire pipeline\n",
    "pipe = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "params_2 = {\n",
    "    'vect__stop_words': (None, 'english'),\n",
    "    'vect__min_df': (2, 5),\n",
    "    'clf__max_depth': (10, None)\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(pipe, params_2, cv=5, n_jobs=-1, verbose=1)\n",
    "gs2.fit(newsgroups_train['data'], newsgroups_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6607746264533867"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': None, 'vect__min_df': 2, 'vect__stop_words': 'english'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdIE67Us6uEc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gs2.predict([\"The new york yankees are the best team in the region.\"])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhcb5G0W-Dch"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.baseball'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target_names'][pred[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2R2ACd36uEd"
   },
   "source": [
    "Advantages to using GS with the Pipe:\n",
    "* Allows us to make predictions on raw text increasing reproducibility. :)\n",
    "* Allows us to tune the parameters of the vectorizer along side the classifier. :D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbZjG6U86uEe"
   },
   "source": [
    "# Part 1: Describe how an LDA Model works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMzU-XOM3LzW"
   },
   "source": [
    "[Your Guide to Latent Dirichlet Allocation](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)\n",
    "\n",
    "[LDA Topic Modeling](https://lettier.com/projects/lda-topic-modeling/)\n",
    "\n",
    "[Topic Modeling with Gensim](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yPIlE_IeF0cX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# Download spacy model\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qapChu_UGBFc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaMsy1XAGLxc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'content': newsgroups_train['data'],\n",
    "    'target': newsgroups_train['target'],\n",
    "    'target_names': [newsgroups_train['target_names'][i] for i in newsgroups_train['target']]\n",
    "})\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10478</th>\n",
       "      <td>\\nAs usual, you are missing the whole point, Russell, because you are not\\nwilling to even consider questionning your basic article of faith, which\\nis that science is merely a matter of methodology and that the highest\\npurpose of science is to avoid making mistakes.  \\n\\nThis is like saying that the most important aspect of business management\\nis accurate bookkeeping.  \\n\\nIf science were no more than methodology and not making mistakes, it\\nwould be a poor thing indeed.  What was the methodology of Darwin?  What\\nwas the methodology of Einstein?  What was, for that matter, the\\nmethodology of Jenner and Pasteur?  \\n\\n\\n\\n\\nFirst of all, I think you are arguing against a straw man, because I\\ndon't think that anyone here is arguing that quackery, pseudo-science,\\nhomeopathy, chiropracty, and traditional Chinese medicine should be\\naccepted as science.  I, in particular, think the basic ideas of\\nhomeopathy and chiropracty seem extremely flaky.  \\n\\nWhat some of us do believe, however, is that some of these things\\n(including some of the flaky ideas) are deserving of serious scientific\\nattention.  \\n\\nIf in fact it were true, as you have stated above, that those who do not\\nuse the currently fashionable methodology can have no idea what is\\neffective and what is not, then science today would not exist.  For all\\nof current science is based on the past work of scientists whose\\nmethodology, by current standards, was seriously flawed.  \\n\\nIt is certainly true that as methodology improves, we need to re-examine\\nthose results derived in the past using less perfect methodologies.  It is\\nalso true that the results obtained by people today who still rely on \\nthose early methodologies needs to be re-examined in a more rigorous \\nfashion by those qualified to do so credibly.  \\n\\nBut to say that nobody who fails to do elaborate double-blind studies is\\ncapable of knowing their ass from a hole in the ground and to say that no\\nideas that come from outside the scientific establishment could possibly\\nbe worthy of serious investigation ... this truly marks one's attitude as\\ndoctrinaire, cultist.  This attitude is not compatible with a belief in\\nreason.  \\n\\n--\\nIn the arguments between behaviorists and cognitivists, psychology seems \\nless like a science than a collection of competing religious sects.</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8200</th>\n",
       "      <td>Just a few cheap shots a Christianity:\\n\\nRiddle: What is the shortest street in Jerusalem?\\nAnswer: The Street of the Righteous Poles.\\n\\nLimrick:\\n\\nThere was an archeologist Thostle\\nWho found an amazing fossil\\nBy the way it was bent\\nAnd the knot it the end\\n'twas the penis of Paul the Apostle.\\n\\nJingle:\\nChristianity hits the spot\\nTwelve Apostles thats a lot\\nJesus Christ and a Virgin too\\nChristianity's the faith for you\\n(with apologies to Pepsi Cola and its famous jingle)\\n\\nRiddle:\\nHow many Christians does it take to save a light bulb.\\nAnswer: None, only Jesus can save.\\n\\nAphorism:\\nJesus Saves\\nMoses Invests\\n\\nProof that Jesus was Jewish:\\n1. He lived at home till he was 33\\n2. He went into his fathers business\\n3. He thought he mother was a virgin\\n4. His mother thought he was God.\\n\\nQED.\\n\\nSo long you all\\n\\nBob Kolker\\n\"I would rather spend eternity in Hell with interesting people \\nthan eternity in Heaven with Christians\"\\n\\n</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>Hooray ! I always suspected that I was human too :-)  It is the desire to be like\\nChrist that often causes christians to be very critical of themselves and other\\nchristians. We are supposed to grow, mature, endeavour to be Christ-like but we\\nare far far far from perfect. Build up the body of Christ, don't tear it down,\\nand that includes yourself. Jesus loves me just the way I am today, tomorrow and\\nalways (thank God ! :-).</td>\n",
       "      <td>15</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      content  \\\n",
       "10478  \\nAs usual, you are missing the whole point, Russell, because you are not\\nwilling to even consider questionning your basic article of faith, which\\nis that science is merely a matter of methodology and that the highest\\npurpose of science is to avoid making mistakes.  \\n\\nThis is like saying that the most important aspect of business management\\nis accurate bookkeeping.  \\n\\nIf science were no more than methodology and not making mistakes, it\\nwould be a poor thing indeed.  What was the methodology of Darwin?  What\\nwas the methodology of Einstein?  What was, for that matter, the\\nmethodology of Jenner and Pasteur?  \\n\\n\\n\\n\\nFirst of all, I think you are arguing against a straw man, because I\\ndon't think that anyone here is arguing that quackery, pseudo-science,\\nhomeopathy, chiropracty, and traditional Chinese medicine should be\\naccepted as science.  I, in particular, think the basic ideas of\\nhomeopathy and chiropracty seem extremely flaky.  \\n\\nWhat some of us do believe, however, is that some of these things\\n(including some of the flaky ideas) are deserving of serious scientific\\nattention.  \\n\\nIf in fact it were true, as you have stated above, that those who do not\\nuse the currently fashionable methodology can have no idea what is\\neffective and what is not, then science today would not exist.  For all\\nof current science is based on the past work of scientists whose\\nmethodology, by current standards, was seriously flawed.  \\n\\nIt is certainly true that as methodology improves, we need to re-examine\\nthose results derived in the past using less perfect methodologies.  It is\\nalso true that the results obtained by people today who still rely on \\nthose early methodologies needs to be re-examined in a more rigorous \\nfashion by those qualified to do so credibly.  \\n\\nBut to say that nobody who fails to do elaborate double-blind studies is\\ncapable of knowing their ass from a hole in the ground and to say that no\\nideas that come from outside the scientific establishment could possibly\\nbe worthy of serious investigation ... this truly marks one's attitude as\\ndoctrinaire, cultist.  This attitude is not compatible with a belief in\\nreason.  \\n\\n--\\nIn the arguments between behaviorists and cognitivists, psychology seems \\nless like a science than a collection of competing religious sects.      \n",
       "8200   Just a few cheap shots a Christianity:\\n\\nRiddle: What is the shortest street in Jerusalem?\\nAnswer: The Street of the Righteous Poles.\\n\\nLimrick:\\n\\nThere was an archeologist Thostle\\nWho found an amazing fossil\\nBy the way it was bent\\nAnd the knot it the end\\n'twas the penis of Paul the Apostle.\\n\\nJingle:\\nChristianity hits the spot\\nTwelve Apostles thats a lot\\nJesus Christ and a Virgin too\\nChristianity's the faith for you\\n(with apologies to Pepsi Cola and its famous jingle)\\n\\nRiddle:\\nHow many Christians does it take to save a light bulb.\\nAnswer: None, only Jesus can save.\\n\\nAphorism:\\nJesus Saves\\nMoses Invests\\n\\nProof that Jesus was Jewish:\\n1. He lived at home till he was 33\\n2. He went into his fathers business\\n3. He thought he mother was a virgin\\n4. His mother thought he was God.\\n\\nQED.\\n\\nSo long you all\\n\\nBob Kolker\\n\"I would rather spend eternity in Hell with interesting people \\nthan eternity in Heaven with Christians\"\\n\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "1682   Hooray ! I always suspected that I was human too :-)  It is the desire to be like\\nChrist that often causes christians to be very critical of themselves and other\\nchristians. We are supposed to grow, mature, endeavour to be Christ-like but we\\nare far far far from perfect. Build up the body of Christ, don't tear it down,\\nand that includes yourself. Jesus loves me just the way I am today, tomorrow and\\nalways (thank God ! :-).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "\n",
       "       target            target_names  \n",
       "10478  13      sci.med                 \n",
       "8200   19      talk.religion.misc      \n",
       "1682   15      soc.religion.christian  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 0)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the apple has fallen from the tree'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to deal with white space\n",
    "\n",
    "'  the apple has fallen from the tree '.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the apple has fallen from the tre'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to deal with white space part du\n",
    "\n",
    "' '.join('   the apple has fallen   from the tre   '.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "na2bkOcFGter"
   },
   "outputs": [],
   "source": [
    "# 1. Remove new line characters\n",
    "df['clean_text'] = df['content'].apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "# 2. Remove extra whitespace \n",
    "df['clean_text'] = df['clean_text'].apply(lambda x: ' '.join(x.split()))\n",
    "# 3. Remove Emails\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x: re.sub('From: \\S+@\\S+', '', x))\n",
    "# 4. Remove non-alphanumeric characters\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2prKILFo3Lzg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>There is another useful method based on Least Sqyares Estimation of the sphere equation parameters.\\n\\nThe points (x,y,z) on a spherical surface with radius R and center (a,b,c) can be written as \\n\\n   (x-a)^2 + (y-b)^2 + (z-c)^2 = R^2\\n\\nThis equation can be rewritten into the following form:  \\n\\n   2ax + 2by + 2cz + R^2 - a^2 - b^2 -c^2 = x^2 + y^2 + z^2\\n\\nApproximate the left hand part by   F(x,y,z) = p1.x + p2.x + p3.z + p4.1\\n\\nFor all datapoints, i.c. 4, determine the 4 parameters p1..p4 which minimise the average error |F(x,y,z) - x^2 - y^2 - z^2|^2.\\n\\nIn 'Numerical Recipes in C' can be found algorithms to solve these parameters.\\n\\nThe best fitting sphere will have \\n- center (a,b,c) = (p1/2, p2/2, p3/2)\\n- radius R = sqrt(p4 + a.a + b.b + c.c).\\n\\nSo, at last, will this solve you sphere estination problem, at least for the most situations I think ?.</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>There is another useful method based on Least Sqyares Estimation of the sphere equation parameters  The points  x y z  on a spherical surface with radius R and center  a b c  can be written as  x a       y b       z c      R   This equation can be rewritten into the following form   ax    by    cz   R     a     b    c     x     y     z   Approximate the left hand part by F x y z    p  x   p  x   p  z   p    For all datapoints  i c     determine the   parameters p   p  which minimise the average error  F x y z    x     y     z       In  Numerical Recipes in C  can be found algorithms to solve these parameters  The best fitting sphere will have   center  a b c     p     p     p       radius R   sqrt p    a a   b b   c c   So  at last  will this solve you sphere estination problem  at least for the most situations I think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10430</th>\n",
       "      <td>##I strongly suggest that you look up a book called THE BIBLE, THE QURAN, AND\\n##SCIENCE by Maurice Baucaille, a French surgeon.  It is not comprehensive,\\n##but, it is well researched.  I imagine your library has it or can get it\\n##for you through interlibrary loan.\\n##\\n\\n  I shall try to get hold of it (when I have time to read of course :-)\\n\\n##In short, Dr Baucaille began investigating the Bible because of pre-\\n##ceived scientific inaccuracies and inconsistencies.  He assumed that\\n##some of the problems may have been caused by poor translations in by-\\n##gone days.  So, he read what he could find in Hebrew, Greek, Aramaic.\\n##What he found was that the problems didn't go away, they got worse.\\n##Then, he decided to see if other religions had the same problems.\\n##So, he picked up the Holy Qur'an (in French) and found similar prob-\\n##lems, but not as many.  SO, he applied the same logoic as he had\\n##with the Bible: he learned to read it in Arabic.  The problems he\\n##had found with the French version went away in Arabic.  He was unable\\n##to find a wealth of scientific statements in the Holy Qur'an, but,\\n##what he did find made sense with modern understanding.  So, he\\n##investigated the Traditions (the hadith) to see what they had to\\n##say about science.  they were filled with science problems; after\\n##all, they were contemporary narratives from a time which had, by\\n##pour standards, a primitive world view.  His conclusion was that,\\n##while he was impressed that what little the Holy Qur'an had to\\n##say about science was accurate, he was far more impressed that the\\n##Holy Qur'an did not contain the same rampant errors evidenced in\\n##the Traditions.  How would a man of 7th Century Arabia have known\\n##what *not to include* in the Holy Qur'an (assuming he had authored\\n##it)?  \\n##\\n\\n    So in short the writer (or writers) of Quran decided to stay away from\\nscience.  (if you do not open your mouth, then you don't put you foot into\\nyour mouth either). \\n\\n   But then if you say Quran does not talk much about science, then one can\\nnot make claims (like Bobby does) that you have great science in Quran.\\n\\n   Basically I want to say that *none* of the religious texts are supposed to\\nbe scientific treatises. So I am just requesting the theists to stop making\\nsuch wild claims.\\n\\n--- Vinayak\\n-------------------------------------------------------\\n                                           vinayak dutt\\n                                   e-mail: vdp@mayo.edu\\n\\n             standard disclaimers apply</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>I strongly suggest that you look up a book called THE BIBLE  THE QURAN  AND   SCIENCE by Maurice Baucaille  a French surgeon  It is not comprehensive    but  it is well researched  I imagine your library has it or can get it   for you through interlibrary loan     I shall try to get hold of it  when I have time to read of course       In short  Dr Baucaille began investigating the Bible because of pre    ceived scientific inaccuracies and inconsistencies  He assumed that   some of the problems may have been caused by poor translations in by    gone days  So  he read what he could find in Hebrew  Greek  Aramaic    What he found was that the problems didn t go away  they got worse    Then  he decided to see if other religions had the same problems    So  he picked up the Holy Qur an  in French  and found similar prob    lems  but not as many  SO  he applied the same logoic as he had   with the Bible  he learned to read it in Arabic  The problems he   had found with the French version went away in Arabic  He was unable   to find a wealth of scientific statements in the Holy Qur an  but    what he did find made sense with modern understanding  So  he   investigated the Traditions  the hadith  to see what they had to   say about science  they were filled with science problems  after   all  they were contemporary narratives from a time which had  by   pour standards  a primitive world view  His conclusion was that    while he was impressed that what little the Holy Qur an had to   say about science was accurate  he was far more impressed that the   Holy Qur an did not contain the same rampant errors evidenced in   the Traditions  How would a man of  th Century Arabia have known   what  not to include  in the Holy Qur an  assuming he had authored   it      So in short the writer  or writers  of Quran decided to stay away from science   if you do not open your mouth  then you don t put you foot into your mouth either   But then if you say Quran does not talk much about science  then one can not make claims  like Bobby does  that you have great science in Quran  Basically I want to say that  none  of the religious texts are supposed to be scientific treatises  So I am just requesting the theists to stop making such wild claims      Vinayak                                                         vinayak dutt e mail  vdp mayo edu standard disclaimers apply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>#Yet, when a law was proposed for Virginia that extended this \\n#philosophy to cigarette smokers (so that people who smoked away\\n#from the work couldn't be discriminated against by employers),\\n#the liberal Gov. Wilder vetoed it.  Which shows that liberals don't\\n#give a damn about \"best person for the job,\" it's just a power\\n#play.\\n\\nOf course Clayton ignores the fact that employers pay health\\ninsurance, and insurance for smokers is more expensive than for\\nnon-smokers. \\n</td>\n",
       "      <td>18</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>Yet  when a law was proposed for Virginia that extended this  philosophy to cigarette smokers  so that people who smoked away  from the work couldn t be discriminated against by employers    the liberal Gov  Wilder vetoed it  Which shows that liberals don t  give a damn about  best person for the job   it s just a power  play  Of course Clayton ignores the fact that employers pay health insurance  and insurance for smokers is more expensive than for non smokers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  content  \\\n",
       "2456   There is another useful method based on Least Sqyares Estimation of the sphere equation parameters.\\n\\nThe points (x,y,z) on a spherical surface with radius R and center (a,b,c) can be written as \\n\\n   (x-a)^2 + (y-b)^2 + (z-c)^2 = R^2\\n\\nThis equation can be rewritten into the following form:  \\n\\n   2ax + 2by + 2cz + R^2 - a^2 - b^2 -c^2 = x^2 + y^2 + z^2\\n\\nApproximate the left hand part by   F(x,y,z) = p1.x + p2.x + p3.z + p4.1\\n\\nFor all datapoints, i.c. 4, determine the 4 parameters p1..p4 which minimise the average error |F(x,y,z) - x^2 - y^2 - z^2|^2.\\n\\nIn 'Numerical Recipes in C' can be found algorithms to solve these parameters.\\n\\nThe best fitting sphere will have \\n- center (a,b,c) = (p1/2, p2/2, p3/2)\\n- radius R = sqrt(p4 + a.a + b.b + c.c).\\n\\nSo, at last, will this solve you sphere estination problem, at least for the most situations I think ?.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "10430  ##I strongly suggest that you look up a book called THE BIBLE, THE QURAN, AND\\n##SCIENCE by Maurice Baucaille, a French surgeon.  It is not comprehensive,\\n##but, it is well researched.  I imagine your library has it or can get it\\n##for you through interlibrary loan.\\n##\\n\\n  I shall try to get hold of it (when I have time to read of course :-)\\n\\n##In short, Dr Baucaille began investigating the Bible because of pre-\\n##ceived scientific inaccuracies and inconsistencies.  He assumed that\\n##some of the problems may have been caused by poor translations in by-\\n##gone days.  So, he read what he could find in Hebrew, Greek, Aramaic.\\n##What he found was that the problems didn't go away, they got worse.\\n##Then, he decided to see if other religions had the same problems.\\n##So, he picked up the Holy Qur'an (in French) and found similar prob-\\n##lems, but not as many.  SO, he applied the same logoic as he had\\n##with the Bible: he learned to read it in Arabic.  The problems he\\n##had found with the French version went away in Arabic.  He was unable\\n##to find a wealth of scientific statements in the Holy Qur'an, but,\\n##what he did find made sense with modern understanding.  So, he\\n##investigated the Traditions (the hadith) to see what they had to\\n##say about science.  they were filled with science problems; after\\n##all, they were contemporary narratives from a time which had, by\\n##pour standards, a primitive world view.  His conclusion was that,\\n##while he was impressed that what little the Holy Qur'an had to\\n##say about science was accurate, he was far more impressed that the\\n##Holy Qur'an did not contain the same rampant errors evidenced in\\n##the Traditions.  How would a man of 7th Century Arabia have known\\n##what *not to include* in the Holy Qur'an (assuming he had authored\\n##it)?  \\n##\\n\\n    So in short the writer (or writers) of Quran decided to stay away from\\nscience.  (if you do not open your mouth, then you don't put you foot into\\nyour mouth either). \\n\\n   But then if you say Quran does not talk much about science, then one can\\nnot make claims (like Bobby does) that you have great science in Quran.\\n\\n   Basically I want to say that *none* of the religious texts are supposed to\\nbe scientific treatises. So I am just requesting the theists to stop making\\nsuch wild claims.\\n\\n--- Vinayak\\n-------------------------------------------------------\\n                                           vinayak dutt\\n                                   e-mail: vdp@mayo.edu\\n\\n             standard disclaimers apply   \n",
       "2336   #Yet, when a law was proposed for Virginia that extended this \\n#philosophy to cigarette smokers (so that people who smoked away\\n#from the work couldn't be discriminated against by employers),\\n#the liberal Gov. Wilder vetoed it.  Which shows that liberals don't\\n#give a damn about \"best person for the job,\" it's just a power\\n#play.\\n\\nOf course Clayton ignores the fact that employers pay health\\ninsurance, and insurance for smokers is more expensive than for\\nnon-smokers. \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "       target        target_names  \\\n",
       "2456   1       comp.graphics        \n",
       "10430  0       alt.atheism          \n",
       "2336   18      talk.politics.misc   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  clean_text  \n",
       "2456   There is another useful method based on Least Sqyares Estimation of the sphere equation parameters  The points  x y z  on a spherical surface with radius R and center  a b c  can be written as  x a       y b       z c      R   This equation can be rewritten into the following form   ax    by    cz   R     a     b    c     x     y     z   Approximate the left hand part by F x y z    p  x   p  x   p  z   p    For all datapoints  i c     determine the   parameters p   p  which minimise the average error  F x y z    x     y     z       In  Numerical Recipes in C  can be found algorithms to solve these parameters  The best fitting sphere will have   center  a b c     p     p     p       radius R   sqrt p    a a   b b   c c   So  at last  will this solve you sphere estination problem  at least for the most situations I think                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "10430    I strongly suggest that you look up a book called THE BIBLE  THE QURAN  AND   SCIENCE by Maurice Baucaille  a French surgeon  It is not comprehensive    but  it is well researched  I imagine your library has it or can get it   for you through interlibrary loan     I shall try to get hold of it  when I have time to read of course       In short  Dr Baucaille began investigating the Bible because of pre    ceived scientific inaccuracies and inconsistencies  He assumed that   some of the problems may have been caused by poor translations in by    gone days  So  he read what he could find in Hebrew  Greek  Aramaic    What he found was that the problems didn t go away  they got worse    Then  he decided to see if other religions had the same problems    So  he picked up the Holy Qur an  in French  and found similar prob    lems  but not as many  SO  he applied the same logoic as he had   with the Bible  he learned to read it in Arabic  The problems he   had found with the French version went away in Arabic  He was unable   to find a wealth of scientific statements in the Holy Qur an  but    what he did find made sense with modern understanding  So  he   investigated the Traditions  the hadith  to see what they had to   say about science  they were filled with science problems  after   all  they were contemporary narratives from a time which had  by   pour standards  a primitive world view  His conclusion was that    while he was impressed that what little the Holy Qur an had to   say about science was accurate  he was far more impressed that the   Holy Qur an did not contain the same rampant errors evidenced in   the Traditions  How would a man of  th Century Arabia have known   what  not to include  in the Holy Qur an  assuming he had authored   it      So in short the writer  or writers  of Quran decided to stay away from science   if you do not open your mouth  then you don t put you foot into your mouth either   But then if you say Quran does not talk much about science  then one can not make claims  like Bobby does  that you have great science in Quran  Basically I want to say that  none  of the religious texts are supposed to be scientific treatises  So I am just requesting the theists to stop making such wild claims      Vinayak                                                         vinayak dutt e mail  vdp mayo edu standard disclaimers apply  \n",
       "2336    Yet  when a law was proposed for Virginia that extended this  philosophy to cigarette smokers  so that people who smoked away  from the work couldn t be discriminated against by employers    the liberal Gov  Wilder vetoed it  Which shows that liberals don t  give a damn about  best person for the job   it s just a power  play  Of course Clayton ignores the fact that employers pay health insurance  and insurance for smokers is more expensive than for non smokers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSW10Cb33Lzk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkgfv9tc3Lzi"
   },
   "outputs": [],
   "source": [
    "# Leverage tqdm for progress_apply\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# If you're on macOS, Linux, or python session executed from Windows Subsystem for Linux (WSL)\n",
    "# conda activate U4-S1-NLP\n",
    "# pip install pandarallel\n",
    "#\n",
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize(progress_bar=True)\n",
    "#\n",
    "# df['lemmas'] = df['content'].parallel_apply(get_lemmas)\n",
    "#\n",
    "# Ref: https://github.com/nalepae/pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EBPQXqEKE9P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11314/11314 [06:07<00:00, 30.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create 'lemmas' column\n",
    "def get_lemmas(x):\n",
    "    lemmas = []\n",
    "    for token in nlp(x):\n",
    "        if (token.is_stop!=True) and (token.is_punct!=True):\n",
    "            lemmas.append(token.lemma_)\n",
    "    return lemmas\n",
    "\n",
    "df['lemmas'] = df['clean_text'].progress_apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yvsyIpvKBlw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>I was wondering if anyone out there could enlighten me on this car I saw the other day  It was a   door sports car  looked to be from the late   s  early   s  It was called a Bricklin  The doors were really small  In addition  the front bumper was separate from the rest of the body  This is all I know  If anyone can tellme a model name  engine specs  years of production  where this car is made  history  or whatever info you have on this funky looking car  please e mail</td>\n",
       "      <td>[wonder, enlighten, car, see, day,  ,   , door, sport, car,  , look, late,   , s,  , early,   , s,  , call, Bricklin,  , door, small,  , addition,  , bumper, separate, rest, body,  , know,  , tellme, model,  , engine, spec,  , year, production,  , car,  , history,  , info, funky, look, car,  , e, mail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>A fair number of brave souls who upgraded their SI clock oscillator have shared their experiences for this poll  Please send a brief message detailing your experiences with the procedure  Top speed attained  CPU rated speed  add on cards and adapters  heat sinks  hour of usage per day  floppy disk functionality with     and     m floppies are especially requested  I will be summarizing in the next two days  so please add to the network knowledge base if you have done the clock upgrade and haven t answered this poll  Thanks</td>\n",
       "      <td>[fair, number, brave, soul, upgrade, SI, clock, oscillator, share, experience, poll,  , send, brief, message, detail, experience, procedure,  , speed, attain,  , cpu, rate, speed,  , add, card, adapter,  , heat, sink,  , hour, usage, day,  , floppy, disk, functionality,     ,     , m, floppy, especially, request,  , summarize, day,  , add, network, knowledge, base, clock, upgrade, haven, t, answer, poll,  , thank]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i'm in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni'm looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i'd heard the 185c was supposed to make an\\nappearence \"this summer\" but haven't heard anymore on it - and since i\\ndon't have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo's just went through recently?\\n\\n* what's the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don't really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i've only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i'll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\  twillis@ecn.purdue.edu    \\    Purdue Electrical Engineering</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>well folks  my mac plus finally gave up the ghost this weekend after starting life as a    k way back in       sooo  i m in the market for a new machine a bit sooner than i intended to be    i m looking into picking up a powerbook     or maybe     and have a bunch of questions that  hopefully  somebody can answer    does anybody know any dirt on when the next round of powerbook introductions are expected  i d heard the    c was supposed to make an appearence  this summer  but haven t heard anymore on it   and since i don t have access to macleak  i was wondering if anybody out there had more info      has anybody heard rumors about price drops to the powerbook line like the ones the duo s just went through recently    what s the impression of the display on the      i could probably swing a     if i got the   Mb disk rather than the      but i don t really have a feel for how much  better  the display is  yea  it looks great in the store  but is that all  wow  or is it really that good    could i solicit some opinions of people who use the     and     day to day on if its worth taking the disk size and money hit to get the active display   i realize this is a real subjective question  but i ve only played around with the machines in a computer store breifly and figured the opinions of somebody who actually uses the machine daily might prove helpful     how well does hellcats perform     thanks a bunch in advance for any info   if you could email  i ll post a summary  news reading time is at a premium with finals just around the corner            Tom Willis   twillis ecn purdue edu   Purdue Electrical Engineering</td>\n",
       "      <td>[folk,  , mac, plus, finally, give, ghost, weekend, start, life,    , k, way,       , sooo,  , m, market, new, machine, bit, sooner, intend,    , m, look, pick, powerbook,     , maybe,     , bunch, question,  , hopefully,  , somebody, answer,    , anybody, know, dirt, round, powerbook, introduction, expect,  , d, hear,    , c, suppose, appearence,  , summer,  , haven, t, hear, anymore,   , don, t, access, macleak,  , wonder, anybody, info,      , anybody, hear, rumor, price, drop, powerbook, line, like, one, duo, s, go, recently,    , s, impression, display,      , probably, swing,     , get,   , Mb, disk,      , don, t, feel,  , ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  I'd like to get some information\\nabout this chip.\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>Do you have Weitek s address phone number  I d like to get some information about this chip</td>\n",
       "      <td>[Weitek, s, address, phone, number,  , d, like, information, chip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by tombaker@world.std.com (Tom A Baker):\\n\\n\\nMy understanding is that the 'expected errors' are basically\\nknown bugs in the warning system software - things are checked\\nthat don't have the right values in yet because they aren't\\nset till after launch, and suchlike. Rather than fix the code\\nand possibly introduce new bugs, they just tell the crew\\n'ok, if you see a warning no. 213 before liftoff, ignore it'.</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>From article  C owCB n p world std com   by tombaker world std com  Tom A Baker   My understanding is that the  expected errors  are basically known bugs in the warning system software   things are checked that don t have the right values in yet because they aren t set till after launch  and suchlike  Rather than fix the code and possibly introduce new bugs  they just tell the crew  ok  if you see a warning no      before liftoff  ignore it</td>\n",
       "      <td>[article,  , C, owcb, n, p, world, std, com,   , tombaker, world, std, com,  , Tom, Baker,   , understanding,  , expect, error,  , basically, know, bug, warning, system, software,   , thing, check, don, t, right, value, aren, t, set, till, launch,  , suchlike,  , fix, code, possibly, introduce, new, bug,  , tell, crew,  , ok,  , warning,      , liftoff,  , ignore,  ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       content  \\\n",
       "0  I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "1  A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "2  well folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i'm in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni'm looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i'd heard the 185c was supposed to make an\\nappearence \"this summer\" but haven't heard anymore on it - and since i\\ndon't have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo's just went through recently?\\n\\n* what's the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don't really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i've only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i'll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\  twillis@ecn.purdue.edu    \\    Purdue Electrical Engineering   \n",
       "3  \\nDo you have Weitek's address/phone number?  I'd like to get some information\\nabout this chip.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "4  From article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker):\\n\\n\\nMy understanding is that the 'expected errors' are basically\\nknown bugs in the warning system software - things are checked\\nthat don't have the right values in yet because they aren't\\nset till after launch, and suchlike. Rather than fix the code\\nand possibly introduce new bugs, they just tell the crew\\n'ok, if you see a warning no. 213 before liftoff, ignore it'.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "\n",
       "   target           target_names  \\\n",
       "0  7       rec.autos               \n",
       "1  4       comp.sys.mac.hardware   \n",
       "2  4       comp.sys.mac.hardware   \n",
       "3  1       comp.graphics           \n",
       "4  14      sci.space               \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                clean_text  \\\n",
       "0  I was wondering if anyone out there could enlighten me on this car I saw the other day  It was a   door sports car  looked to be from the late   s  early   s  It was called a Bricklin  The doors were really small  In addition  the front bumper was separate from the rest of the body  This is all I know  If anyone can tellme a model name  engine specs  years of production  where this car is made  history  or whatever info you have on this funky looking car  please e mail                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "1  A fair number of brave souls who upgraded their SI clock oscillator have shared their experiences for this poll  Please send a brief message detailing your experiences with the procedure  Top speed attained  CPU rated speed  add on cards and adapters  heat sinks  hour of usage per day  floppy disk functionality with     and     m floppies are especially requested  I will be summarizing in the next two days  so please add to the network knowledge base if you have done the clock upgrade and haven t answered this poll  Thanks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "2  well folks  my mac plus finally gave up the ghost this weekend after starting life as a    k way back in       sooo  i m in the market for a new machine a bit sooner than i intended to be    i m looking into picking up a powerbook     or maybe     and have a bunch of questions that  hopefully  somebody can answer    does anybody know any dirt on when the next round of powerbook introductions are expected  i d heard the    c was supposed to make an appearence  this summer  but haven t heard anymore on it   and since i don t have access to macleak  i was wondering if anybody out there had more info      has anybody heard rumors about price drops to the powerbook line like the ones the duo s just went through recently    what s the impression of the display on the      i could probably swing a     if i got the   Mb disk rather than the      but i don t really have a feel for how much  better  the display is  yea  it looks great in the store  but is that all  wow  or is it really that good    could i solicit some opinions of people who use the     and     day to day on if its worth taking the disk size and money hit to get the active display   i realize this is a real subjective question  but i ve only played around with the machines in a computer store breifly and figured the opinions of somebody who actually uses the machine daily might prove helpful     how well does hellcats perform     thanks a bunch in advance for any info   if you could email  i ll post a summary  news reading time is at a premium with finals just around the corner            Tom Willis   twillis ecn purdue edu   Purdue Electrical Engineering   \n",
       "3  Do you have Weitek s address phone number  I d like to get some information about this chip                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "4  From article  C owCB n p world std com   by tombaker world std com  Tom A Baker   My understanding is that the  expected errors  are basically known bugs in the warning system software   things are checked that don t have the right values in yet because they aren t set till after launch  and suchlike  Rather than fix the code and possibly introduce new bugs  they just tell the crew  ok  if you see a warning no      before liftoff  ignore it                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               lemmas  \n",
       "0  [wonder, enlighten, car, see, day,  ,   , door, sport, car,  , look, late,   , s,  , early,   , s,  , call, Bricklin,  , door, small,  , addition,  , bumper, separate, rest, body,  , know,  , tellme, model,  , engine, spec,  , year, production,  , car,  , history,  , info, funky, look, car,  , e, mail]                                                                                                                                                                                                                                                                                                                                                     \n",
       "1  [fair, number, brave, soul, upgrade, SI, clock, oscillator, share, experience, poll,  , send, brief, message, detail, experience, procedure,  , speed, attain,  , cpu, rate, speed,  , add, card, adapter,  , heat, sink,  , hour, usage, day,  , floppy, disk, functionality,     ,     , m, floppy, especially, request,  , summarize, day,  , add, network, knowledge, base, clock, upgrade, haven, t, answer, poll,  , thank]                                                                                                                                                                                                                                   \n",
       "2  [folk,  , mac, plus, finally, give, ghost, weekend, start, life,    , k, way,       , sooo,  , m, market, new, machine, bit, sooner, intend,    , m, look, pick, powerbook,     , maybe,     , bunch, question,  , hopefully,  , somebody, answer,    , anybody, know, dirt, round, powerbook, introduction, expect,  , d, hear,    , c, suppose, appearence,  , summer,  , haven, t, hear, anymore,   , don, t, access, macleak,  , wonder, anybody, info,      , anybody, hear, rumor, price, drop, powerbook, line, like, one, duo, s, go, recently,    , s, impression, display,      , probably, swing,     , get,   , Mb, disk,      , don, t, feel,  , ...]  \n",
       "3  [Weitek, s, address, phone, number,  , d, like, information, chip]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "4  [article,  , C, owcb, n, p, world, std, com,   , tombaker, world, std, com,  , Tom, Baker,   , understanding,  , expect, error,  , basically, know, bug, warning, system, software,   , thing, check, don, t, right, value, aren, t, set, till, launch,  , suchlike,  , fix, code, possibly, introduce, new, bug,  , tell, crew,  , ok,  , warning,      , liftoff,  , ignore,  ]                                                                                                                                                                                                                                                                                   "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPuCuK0z3Lzs"
   },
   "source": [
    "### The two main inputs to the LDA topic model are the dictionary (id2word) and the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1klqRpqtJxWc"
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(df['lemmas'] )\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in df['lemmas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77754"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words do we have?\n",
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove extreme values from the dataset\n",
    "id2word.filter_extremes(no_below=5, no_above=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14778"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words do we have?\n",
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArZPxcP5LH1J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sheet'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IIBnI2e3Lzw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['course',\n",
       " ' ',\n",
       " 'term',\n",
       " 'rigidly',\n",
       " 'define',\n",
       " 'bill',\n",
       " ' ',\n",
       " 'doubt',\n",
       " 'use',\n",
       " 'term',\n",
       " ' ',\n",
       " 'quote',\n",
       " 'allegedly',\n",
       " ' ',\n",
       " ' ',\n",
       " 'read',\n",
       " 'article',\n",
       " 'present',\n",
       " 'argument',\n",
       " 'weapon',\n",
       " 'mass',\n",
       " 'destruction',\n",
       " ' ',\n",
       " 'commonly',\n",
       " 'understand',\n",
       " ' ',\n",
       " 'switch',\n",
       " 'topic',\n",
       " ' ',\n",
       " 'point',\n",
       " 'evidently',\n",
       " 'weapon',\n",
       " 'allow',\n",
       " ' ',\n",
       " 'later',\n",
       " 'analysis',\n",
       " ' ',\n",
       " 'give',\n",
       " 'understanding',\n",
       " ' ',\n",
       " 'consider',\n",
       " 'class']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmas'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGFG9E2j3Lzz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 11),\n",
       " (117, 1),\n",
       " (177, 1),\n",
       " (193, 1),\n",
       " (221, 1),\n",
       " (225, 1),\n",
       " (226, 1),\n",
       " (227, 1),\n",
       " (228, 1),\n",
       " (229, 1),\n",
       " (230, 1),\n",
       " (231, 1),\n",
       " (232, 1),\n",
       " (233, 1),\n",
       " (234, 1),\n",
       " (235, 1),\n",
       " (236, 1),\n",
       " (237, 1),\n",
       " (238, 1),\n",
       " (239, 1),\n",
       " (240, 1),\n",
       " (241, 1),\n",
       " (242, 1),\n",
       " (243, 1),\n",
       " (244, 1),\n",
       " (245, 1),\n",
       " (246, 2),\n",
       " (247, 1),\n",
       " (248, 1),\n",
       " (249, 2)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TB6wox963Lz2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rm'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[252]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kk3g75XX3Lz4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'controller'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6K2jWxHJLOzK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('  ', 11),\n",
       " ('helpful', 1),\n",
       " ('address', 1),\n",
       " ('ignore', 1),\n",
       " ('course', 1),\n",
       " ('evidently', 1),\n",
       " ('later', 1),\n",
       " ('mass', 1),\n",
       " ('point', 1),\n",
       " ('present', 1),\n",
       " ('quote', 1),\n",
       " ('read', 1),\n",
       " ('switch', 1),\n",
       " ('term', 1),\n",
       " ('topic', 1),\n",
       " ('understand', 1),\n",
       " ('weapon', 1),\n",
       " ('News', 1),\n",
       " ('Sean', 1),\n",
       " ('September', 1),\n",
       " ('Sharon', 1),\n",
       " ('accidentally', 1),\n",
       " ('bounce', 1),\n",
       " ('couldn', 1),\n",
       " ('delete', 1),\n",
       " ('directly', 1),\n",
       " ('file', 2),\n",
       " ('glad', 1),\n",
       " ('instead', 1),\n",
       " ('prob', 2)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[(id2word[word_id], word_count) for word_id, word_count in corpus[5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le-XzI923Lz8"
   },
   "source": [
    "# Part 2: Estimate a LDA Model with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AlNG4bSI3Lz8"
   },
   "source": [
    " ### Train an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fasvjf0VLQ2a"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 14778 is out of bounds for axis 1 with size 14778",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    978\u001b[0m                         \u001b[0mpass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_no\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m                     )\n\u001b[0;32m--> 980\u001b[0;31m                     \u001b[0mgammat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_estep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_alpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mdo_estep\u001b[0;34m(self, chunk, state)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msstats\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumdocs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# avoids calling len(chunk) on a generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mexpElogbetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;31m# The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 14778 is out of bounds for axis 1 with size 14778"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=20, \n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            per_word_topics=True)\n",
    "# https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49CabmIj3Lz_"
   },
   "outputs": [],
   "source": [
    "# lda_model.save('lda_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDgUshRE3L0C"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lda_multicore = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=20, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=12)\n",
    "\n",
    "# https://radimrehurek.com/gensim/models/ldamulticore.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rgb9AaPq3L0E"
   },
   "outputs": [],
   "source": [
    "lda_multicore.save('lda_multicore.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLxvJPoK3L0G"
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "lda_multicore =  models.LdaModel.load('lda_multicore.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDH3tzx13L0I"
   },
   "source": [
    "### View the topics in LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JawR8yscLVNS"
   },
   "outputs": [],
   "source": [
    "pprint(lda_multicore.print_topics())\n",
    "doc_lda = lda_multicore[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro = [lda[d] for d in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gKEP0bIC3L0K"
   },
   "source": [
    "### What is topic Perplexity?\n",
    "Perplexity is a statistical measure of how well a probability model predicts a sample. As applied to LDA, for a given value of , you estimate the LDA model. Then given the theoretical word distributions represented by the topics, compare that to the actual topic mixtures, or distribution of words in your documents.\n",
    "\n",
    "### What is topic coherence?\n",
    "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.\n",
    "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is “the game is a team sport”, “the game is played with a ball”, “the game demands great physical efforts”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xCjhr8k4LXSy"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_multicore.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_multicore, \n",
    "                                     texts=df['lemmas'], \n",
    "                                     dictionary=id2word, \n",
    "                                     coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7UvfgYt93L0X"
   },
   "source": [
    "# Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYXi480VLaHK"
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_multicore, corpus, id2word)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjtXk8J3LaXC"
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=num_topics, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=12)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRA9EjvQ3L0c"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, \n",
    "                                                        corpus=corpus, \n",
    "                                                        texts=df['lemmas'], \n",
    "                                                        start=2, \n",
    "                                                        limit=40, \n",
    "                                                        step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2e9X-Ql-3L0e"
   },
   "outputs": [],
   "source": [
    "coherence_values = [0.5054, 0.5332, 0.5452, 0.564, 0.5678, 0.5518, 0.519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybEBYQNF3L0g"
   },
   "outputs": [],
   "source": [
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmvQ2zKZ3L0i"
   },
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yol5vG3R3L0k"
   },
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "#optimal_model = model_list[4]\n",
    "optimal_model =  models.LdaModel.load('optimal_model.model')\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HwVEUDI3L0m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSPT6_LS_DS_414_Topic_Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
